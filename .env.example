# Backend
EMBEDDING_MODEL=semantic-384
LLM_PROVIDER=openai         # options: stub | openai | ollama
OPENAI_API_KEY=put-your-key-here
OLLAMA_HOST=http://ollama:11434
VECTOR_STORE=qdrant         # qdrant | memory
COLLECTION_NAME=policy_helper
CHUNK_SIZE=700
CHUNK_OVERLAP=80

